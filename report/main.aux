\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{nyt/global//global/global}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\abx@aux@cite{neyshabur2018towards}
\abx@aux@segm{0}{0}{neyshabur2018towards}
\abx@aux@cite{zagoruyko2016wide}
\abx@aux@segm{0}{0}{zagoruyko2016wide}
\abx@aux@cite{zhang2016understanding}
\abx@aux@segm{0}{0}{zhang2016understanding}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}}
\abx@aux@page{1}{2}
\abx@aux@page{2}{2}
\abx@aux@page{3}{2}
\abx@aux@cite{rolnick2017deep}
\abx@aux@segm{0}{0}{rolnick2017deep}
\abx@aux@segm{0}{0}{neyshabur2018towards}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Formal background}{3}{subsection.1.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related work}{3}{section.2}}
\newlabel{section:prior}{{2}{3}{Related work}{section.2}{}}
\abx@aux@page{4}{3}
\abx@aux@segm{0}{0}{neyshabur2018towards}
\abx@aux@cite{goldt2019dynamics}
\abx@aux@segm{0}{0}{goldt2019dynamics}
\abx@aux@page{5}{4}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Self-regularization of over-parameterized models}{4}{subsection.2.1}}
\abx@aux@page{6}{4}
\abx@aux@page{7}{4}
\abx@aux@cite{casper2019removable}
\abx@aux@segm{0}{0}{casper2019removable}
\abx@aux@cite{martin2018implicit}
\abx@aux@segm{0}{0}{martin2018implicit}
\abx@aux@cite{nagarajan2019uniform}
\abx@aux@segm{0}{0}{nagarajan2019uniform}
\abx@aux@page{8}{5}
\abx@aux@page{9}{5}
\abx@aux@page{10}{5}
\abx@aux@cite{tian2019luck}
\abx@aux@segm{0}{0}{tian2019luck}
\abx@aux@cite{frankle2018lottery}
\abx@aux@segm{0}{0}{frankle2018lottery}
\abx@aux@cite{brutzkus2019larger}
\abx@aux@segm{0}{0}{brutzkus2019larger}
\abx@aux@cite{han2015learning}
\abx@aux@segm{0}{0}{han2015learning}
\abx@aux@cite{li2016pruning}
\abx@aux@segm{0}{0}{li2016pruning}
\abx@aux@segm{0}{0}{frankle2018lottery}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Advantageous properties of over-parameterized models}{6}{subsection.2.2}}
\abx@aux@page{11}{6}
\abx@aux@page{12}{6}
\abx@aux@page{13}{6}
\abx@aux@page{14}{6}
\abx@aux@page{15}{6}
\abx@aux@page{16}{6}
\abx@aux@cite{liu2018rethinking}
\abx@aux@segm{0}{0}{liu2018rethinking}
\abx@aux@cite{frankle2019lottery}
\abx@aux@segm{0}{0}{frankle2019lottery}
\abx@aux@cite{morcos2019one}
\abx@aux@segm{0}{0}{morcos2019one}
\abx@aux@page{17}{7}
\abx@aux@page{18}{7}
\abx@aux@segm{0}{0}{brutzkus2019larger}
\abx@aux@page{19}{8}
\abx@aux@page{20}{8}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Leveraging model simplicity: Compression and Pruning}{9}{subsection.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{9}{section.3}}
\abx@aux@segm{0}{0}{liu2018rethinking}
\abx@aux@page{21}{10}
\abx@aux@cite{lecun1998gradient}
\abx@aux@segm{0}{0}{lecun1998gradient}
\abx@aux@cite{simonyan2014very}
\abx@aux@segm{0}{0}{simonyan2014very}
\abx@aux@cite{glorot2010understanding}
\abx@aux@segm{0}{0}{glorot2010understanding}
\abx@aux@segm{0}{0}{lecun1998gradient}
\abx@aux@segm{0}{0}{simonyan2014very}
\abx@aux@segm{0}{0}{glorot2010understanding}
\abx@aux@segm{0}{0}{nagarajan2019uniform}
\abx@aux@segm{0}{0}{brutzkus2019larger}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Architectures tested in this project. Convolutions are 3x3. Lenet is from \cite {lecun1998gradient}. Conv-2/4/6 are variants of VGG \nobreakspace  {}\autocite {simonyan2014very}. Initializations are Gaussian Glorot \nobreakspace  {}\autocite {glorot2010understanding}.\relax }}{11}{figure.caption.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Comparison of pruning criteria}{11}{subsection.3.1}}
\abx@aux@page{28}{11}
\abx@aux@page{29}{11}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:lenet-fc1}{{2a}{14}{Pruning the first fully connected layer of LeNet\relax }{figure.caption.11}{}}
\newlabel{sub@fig:lenet-fc1}{{a}{14}{Pruning the first fully connected layer of LeNet\relax }{figure.caption.11}{}}
\newlabel{fig:conv2-fc1}{{2b}{14}{Pruning the first fully connected layer of Conv-2\relax }{figure.caption.11}{}}
\newlabel{sub@fig:conv2-fc1}{{b}{14}{Pruning the first fully connected layer of Conv-2\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Comparison of different pruning metrics. \texttt  {max\_mag\_pruning} (\texttt  {min\_mag\_pruning}) corresponds to \textit  {Magnitude pruning} that maximizes (minimizes) the Frobenius norm of the pruned matrix. \texttt  {max\_fp\_pruning} (\texttt  {min\_fp\_pruning}) corresponds to \textit  {Frame-potential pruning}, it maximizes (minimizes) the frame-potential of the pruned matrix. For random pruning, averages were taken over 5 random experiments. Error bars were added with a width equal to the standard deviation, computed over the 5 random experiments, of the test accuracy obtained after pruning $i$ units.\relax }}{14}{figure.caption.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Visualizing training dynamics}{15}{subsection.3.2}}
\abx@aux@segm{0}{0}{martin2018implicit}
\abx@aux@segm{0}{0}{nagarajan2019uniform}
\abx@aux@segm{0}{0}{brutzkus2019larger}
\abx@aux@page{30}{16}
\abx@aux@page{31}{16}
\abx@aux@page{32}{16}
\newlabel{fig:conv2-fc1-init}{{3a}{18}{At initialization\relax }{figure.caption.14}{}}
\newlabel{sub@fig:conv2-fc1-init}{{a}{18}{At initialization\relax }{figure.caption.14}{}}
\newlabel{fig:conv2-fc1-final}{{3b}{18}{After convergence\relax }{figure.caption.14}{}}
\newlabel{sub@fig:conv2-fc1-final}{{b}{18}{After convergence\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Visualizing the training dynamics of the first fully connected layer of Conv-2\relax }}{18}{figure.caption.14}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Cluster formation in the last convolutional layer of VGG19 during training\relax }}{19}{figure.caption.15}}
\newlabel{fig:vgg-conv16-final}{{4}{19}{Cluster formation in the last convolutional layer of VGG19 during training\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Subspace analysis}{19}{subsection.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Additional results}{19}{subsection.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{19}{section.4}}
\abx@aux@page{33}{20}
\abx@aux@page{34}{20}
\abx@aux@page{35}{20}
\abx@aux@page{36}{20}
\abx@aux@page{37}{20}
\abx@aux@page{38}{20}
\abx@aux@page{39}{20}
\abx@aux@page{40}{20}
\abx@aux@page{41}{20}
\abx@aux@page{42}{20}
\abx@aux@page{43}{20}
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{brutzkus2019larger}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{casper2019removable}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{frankle2018lottery}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{frankle2019lottery}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{glorot2010understanding}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{goldt2019dynamics}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{han2015learning}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{lecun1998gradient}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{li2016pruning}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{liu2018rethinking}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{martin2018implicit}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{morcos2019one}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{nagarajan2019uniform}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{neyshabur2018towards}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{rolnick2017deep}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{simonyan2014very}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{tian2019luck}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{zagoruyko2016wide}{nyt/global//global/global}
\abx@aux@defaultrefcontext{0}{zhang2016understanding}{nyt/global//global/global}
\abx@aux@page{44}{21}
\abx@aux@page{45}{21}
\abx@aux@page{46}{21}
\abx@aux@page{47}{21}
\abx@aux@page{48}{21}
\abx@aux@page{49}{21}
\abx@aux@page{50}{21}
\abx@aux@page{51}{21}
